[script]
name = "tune"
model = ${model}
trainer = ${trainer}
data = ${data}
seed = 42

[task]
@task = "LogitsToPrediction"
num_classes = 1
multilabel = False

[data]
@data = "base-datamodule"
dataset = ${dataset_loader}
tokenizer = ${tokenizer}
batch_size = 32
padding = True

[dataset_loader]
@data = "dataset-from-DF"
data = "/export/home/share/datascientists/ecci/final/all_entities.csv"
save_path = "/data/scratch/tpetitjean/ML/datasets/ecci"

[classification_head]
@classification_head = "simple"
dropout = ${transformer:embeddings.dropout.p}
hidden_size = ${transformer:pooler.dense.out_features}
num_classes = ${task.num_classes}
bias_init = 0.9445 # sig(bias_init) = percentage of pos examples

[transformer]
@model = "transformer"
path = "/data/scratch/tpetitjean/ML/models/camembert-base"

[tokenizer]
@model = "tokenizer"
path = ${transformer.path}

[loss]
@loss = "PytorchLoss"
name = "BCEWithLogitsLoss"
pos_weight = 0.39

[model]
@model = "ecci-qualifier"
transformer = ${transformer}
classification_head = ${classification_head}
loss = ${loss}
optimizer_params = ${optimizer_params}
total_steps = ${trainer:max_steps}
metrics = ${metrics}
task = ${task}
label_dtype = "float"
tokenizer = ${tokenizer}

[trainer]
@trainer = "PytorchLightningTrainer"
max_steps = 800 #1500 #1000
logger = ${logger}
callbacks = [${checkpoint}, ${early_stopping}, ${lr_monitor}]

[trainer.cpu]
accelerator = "auto"
devices = "auto"
strategy = None
[trainer.gpu]
accelerator = "gpu"
devices = -1
strategy = "dp"
auto_select_gpus = True

[optimizer_params]
# The following is computed from either max_steps or max_epochs
total_steps = ${trainer:max_steps}
[optimizer_params.head]
lr = 2e-3
warmup_rate = 0

[optimizer_params.transformer]
lr = 3e-5
warmup_rate = 0.1

[metrics]

[metrics.f1]
@metric = "TorchMetric"
name="F1Score"
task="binary"
dist_sync_on_step=True

[metrics.precision]
@metric = "TorchMetric"
name="Precision"
task="binary"
dist_sync_on_step=True

[metrics.recall]
@metric = "TorchMetric"
name="Recall"
task="binary"
dist_sync_on_step=True


[checkpoint]
@callback = "PytorchLightningCallback"
name = ModelCheckpoint
monitor = "valid/f1"
mode = "max"
save_top_k = 1
verbose = True
every_n_epochs = 1
dirpath = "/data/scratch/tpetitjean/ML/checkpoints_test"
auto_insert_metric_name = False
save_weights_only = True

[early_stopping]
@callback = "PytorchLightningCallback"
name = EarlyStopping
monitor = "valid/f1"
patience = 3
mode = "max"

[lr_monitor]
@callback = "PytorchLightningCallback"
name = LearningRateMonitor
logging_interval = "epoch"

[logger]
@logger = "TensorBoard"
save_dir = "~/tensorboard_data"
name = ${script.name}
default_hp_metric = False
